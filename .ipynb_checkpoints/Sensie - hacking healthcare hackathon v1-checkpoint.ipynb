{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/mash/Downloads/Sensie_download_02-16-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mash/Downloads/Sensie_download_02-16-2018'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train set shape  (2440, 903)\n",
      "Raw test set shape  (1045, 903)\n",
      "Train set shape W/O NAN  (2363, 903)\n",
      "Test set shape W/O NAN  (1014, 903)\n",
      "Final train set shape  (2363, 900)\n",
      "Final train expected outcome set shape  (2363,)\n",
      "Final test set shape  (1014, 900)\n",
      "Final test expected outcome set shape  (1014,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "\n",
    "# data format being loaded: \n",
    "# no headers\n",
    "# first column is the \"tag\" or expected outcom, 0 is \"Stress present\", 1 si\"Stress free\"\n",
    "# second column is the user's email\n",
    "# third column indicates if the user is left handed (represented by a 1) or right handed (represented by 0)\n",
    "# columns 4 to 903 (inclusive) represent gyroscope data gatered for 3 seconds at 100Hz \n",
    "# columns 4 to 303 (inclusive) are for Yaw\n",
    "# columns 304 to 603 (inclusive) are for Roll\n",
    "# columns 604 to 903 (inclusive) are for Pitch\n",
    "\n",
    "test_data = genfromtxt('MasterShuffle_test.csv', delimiter=',', skip_header=1)\n",
    "train_data = genfromtxt('MasterShuffle_train.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "print(\"Raw train set shape \",train_data.shape)\n",
    "print(\"Raw test set shape \",test_data.shape)\n",
    "\n",
    "# eliminate NaN's\n",
    "test_data = np.delete(test_data, np.unique(np.argwhere(np.isnan(test_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "train_data = np.delete(train_data, np.unique(np.argwhere(np.isnan(train_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "\n",
    "print(\"Train set shape W/O NAN \",train_data.shape)\n",
    "print(\"Test set shape W/O NAN \",test_data.shape)\n",
    "\n",
    "\n",
    "Y_train_orig = train_data[:,0].astype(int)\n",
    "X_train_orig = train_data[:,3:]\n",
    "\n",
    "\n",
    "Y_test_orig = test_data[:,0].astype(int)\n",
    "X_test_orig = test_data[:,3:]\n",
    "\n",
    "\n",
    "print(\"Final train set shape \",X_train_orig.shape)\n",
    "print(\"Final train expected outcome set shape \",Y_train_orig.shape)\n",
    "\n",
    "\n",
    "print(\"Final test set shape \",X_test_orig.shape)\n",
    "print(\"Final test expected outcome set shape \",Y_test_orig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensie combined dataframe with NaN samples shape  (10462, 304)\n",
      "Appended combined dataframe shape  (3377, 903)\n"
     ]
    }
   ],
   "source": [
    "## Combining the raw provided ShuffleMaster train & test tables for AzureML modeling\n",
    "sensie_times = genfromtxt('sensie_timeseries_data.csv', delimiter=',', skip_header=0)\n",
    "\n",
    "print(\"Sensie combined dataframe with NaN samples shape \",sensie_times.shape)\n",
    "print(\"Appended combined dataframe shape \",sensie.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2363 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     1\n",
       "2     1\n",
       "3     0\n",
       "4     1\n",
       "5     1\n",
       "6     0\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    0\n",
       "18    0\n",
       "19    0\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    1\n",
       "...  ..\n",
       "2333  1\n",
       "2334  1\n",
       "2335  1\n",
       "2336  1\n",
       "2337  0\n",
       "2338  1\n",
       "2339  0\n",
       "2340  1\n",
       "2341  0\n",
       "2342  1\n",
       "2343  1\n",
       "2344  0\n",
       "2345  1\n",
       "2346  1\n",
       "2347  1\n",
       "2348  1\n",
       "2349  0\n",
       "2350  0\n",
       "2351  0\n",
       "2352  0\n",
       "2353  0\n",
       "2354  0\n",
       "2355  0\n",
       "2356  0\n",
       "2357  0\n",
       "2358  0\n",
       "2359  1\n",
       "2360  0\n",
       "2361  0\n",
       "2362  1\n",
       "\n",
       "[2363 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate NaN's\n",
    "sensie_times = np.delete(sensie_times, np.unique(np.argwhere(np.isnan(sensie_times[:,3:])).T[0].flatten('C')), axis=0)\n",
    "sensie_times = train_data[:,0].astype(int)\n",
    "\n",
    "sensie_times = pd.DataFrame(sensie_times)\n",
    "sensie_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {'state': ['Ohio', 'CA'], 'year': [2000, 2010]}\n",
    "df1 = pd.DataFrame(dict1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train set shape  (2440, 903)\n",
      "Full test set shape  (1045, 903)\n",
      "Train set shape without NAN records  (2363, 903)\n",
      "Test set shape without NAN records  (1014, 903)\n",
      "Final train set shape  (2363, 900)\n",
      "Final train expected outcome set shape  (2363,)\n",
      "Final test set shape  (1014, 900)\n",
      "Final test expected outcome set shape  (1014,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "# data format being loaded: \n",
    "# no headers\n",
    "# first column is the \"tag\" or expected outcom, 0 is \"Stress present\", 1 is \"Stress free\"\n",
    "# second column is the user's email\n",
    "# third column indicates if the user is left handed (represented by a 1) or right handed (represented by 0)\n",
    "# columns 4 to 903 (inclusive) represent gyroscope data gatered for 3 seconds at 100Hz \n",
    "# columns 4 to 303 (inclusive) are for Yaw\n",
    "# columns 304 to 603 (inclusive) are for Roll\n",
    "# columns 604 to 903 (inclusive) are for Pitch\n",
    "\n",
    "test_data = genfromtxt('MasterShuffle_test.csv', delimiter=',', skip_header=1)\n",
    "train_data = genfromtxt('MasterShuffle_train.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Full train set shape \",train_data.shape)\n",
    "print(\"Full test set shape \",test_data.shape)\n",
    "\n",
    "\n",
    "#eliminate NaN's\n",
    "test_data = np.delete(test_data, np.unique(np.argwhere(np.isnan(test_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "train_data = np.delete(train_data, np.unique(np.argwhere(np.isnan(train_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train set shape without NAN records \",train_data.shape)\n",
    "print(\"Test set shape without NAN records \",test_data.shape)\n",
    "\n",
    "\n",
    "Y_train_orig = train_data[:,0].astype(int)\n",
    "X_train_orig = train_data[:,3:]\n",
    "\n",
    "\n",
    "Y_test_orig = test_data[:,0].astype(int)\n",
    "X_test_orig = test_data[:,3:]\n",
    "\n",
    "\n",
    "print(\"Final train set shape \",X_train_orig.shape)\n",
    "print(\"Final train expected outcome set shape \",Y_train_orig.shape)\n",
    "\n",
    "\n",
    "print(\"Final test set shape \",X_test_orig.shape)\n",
    "print(\"Final test expected outcome set shape \",Y_test_orig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Constants\n",
    "\n",
    "# Those are separate normalised input features for the neural network\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    \"body_acc_x_\",\n",
    "    \"body_acc_y_\",\n",
    "    \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"STRESSED\", \n",
    "    \"NOT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Additionnal Parameters:</b><br>\n",
    "\n",
    "Here are some core parameter definitions for the training.\n",
    "\n",
    "The whole neural network's structure could be summarised by enumerating those parameters and the fact an LSTM is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363\n",
      "1014\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "training_data_count = len(X_train_orig)\n",
    "test_data_count = len(X_test_orig)\n",
    "n_steps = len(X_train_orig[0])\n",
    "##n_input = len(X_train_orig[0][0])\n",
    "\n",
    "print(training_data_count)\n",
    "print(test_data_count)\n",
    "print(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-01844123148d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some useful info to get an insight on dataset's shape and normalisation:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(X shape, y shape, every X's mean, every X's standard deviation)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_orig' is not defined"
     ]
    }
   ],
   "source": [
    "# Input Data \n",
    "\n",
    "training_data_count = len(X_train_orig)  # 2363 training series (with 50% overlap between each series)\n",
    "test_data_count = len(X_test_orig)  # 1014 testing series\n",
    "n_steps = len(X_train_orig[0])  # 900 timesteps per series = 3 * 3 sec * 100 Hz\n",
    "# n_input = len(X_train_orig[0][0])  # This will have to be hardcoded\n",
    "n_input = 3\n",
    "\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "\n",
    "n_hidden = 32 # Hidden layer num of features\n",
    "n_classes = 6 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "batch_size = 1500\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test_orig.shape, y_test_orig.shape, np.mean(X_test_orig), np.std(X_test_orig))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download necessary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mash/kdata/kaggle\n",
      "Introduction to TensorFlow and Sentiment Analysis.pdf\n",
      "Kaggle_001 - exploratory analysis.ipynb\n",
      "MashModel.ipynb\n",
      "README.md\n",
      "Sensie - hacking healthcare hackathon v1.ipynb\n",
      "TensorFlow_Regression.html\n",
      "TensorFlow_Regression.ipynb\n",
      "classes.csv\n",
      "directoryImageID_explore.R\n",
      "image001.jpg\n",
      "nuclei.html\n",
      "nuclei.ipynb\n",
      "nuclei.yml\n",
      "stuff.csv\n"
     ]
    }
   ],
   "source": [
    "!pwd && ls\n",
    "\n",
    "test_data = genfromtxt('/Users/mash/Downloads/Sensie_download_02-16-2018/'+'sensie_prepared_data.csv', delimiter=',', skip_header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mash/kdata/kaggle'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ERRORS OUT\n",
    "\n",
    "download_path = \"~/Users/mash/Downloads/Sensie_download_02-16-2018/\"\n",
    "def load_data(datafile):\n",
    "    time_series_data = []\n",
    "    \n",
    "    for file_path in datafile:\n",
    "        file = open(file_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        time_series_data.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "    \n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "data = load_data(download_path + 'sensie_prepared_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.        ,  8.63157895,  9.26315789,  9.89473684, 10.52631579,\n",
       "       11.15789474, 11.78947368, 12.42105263, 13.05263158, 13.68421053,\n",
       "       14.31578947, 14.94736842, 15.57894737, 16.21052632, 16.84210526,\n",
       "       17.47368421, 18.10526316, 18.73684211, 19.36842105, 20.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(8,20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
