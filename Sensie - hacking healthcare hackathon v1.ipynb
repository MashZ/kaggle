{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/mash/Downloads/Sensie_download_02-16-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mash/Downloads/Sensie_download_02-16-2018'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train set shape  (2440, 903)\n",
      "Raw test set shape  (1045, 903)\n",
      "Train set shape W/O NAN  (2363, 903)\n",
      "Test set shape W/O NAN  (1014, 903)\n",
      "Final train set shape  (2363, 900)\n",
      "Final train expected outcome set shape  (2363,)\n",
      "Final test set shape  (1014, 900)\n",
      "Final test expected outcome set shape  (1014,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "\n",
    "# data format being loaded: \n",
    "# no headers\n",
    "# first column is the \"tag\" or expected outcom, 0 is \"Stress present\", 1 si\"Stress free\"\n",
    "# second column is the user's email\n",
    "# third column indicates if the user is left handed (represented by a 1) or right handed (represented by 0)\n",
    "# columns 4 to 903 (inclusive) represent gyroscope data gatered for 3 seconds at 100Hz \n",
    "# columns 4 to 303 (inclusive) are for Yaw\n",
    "# columns 304 to 603 (inclusive) are for Roll\n",
    "# columns 604 to 903 (inclusive) are for Pitch\n",
    "\n",
    "test_data = genfromtxt('MasterShuffle_test.csv', delimiter=',', skip_header=1)\n",
    "train_data = genfromtxt('MasterShuffle_train.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "print(\"Raw train set shape \",train_data.shape)\n",
    "print(\"Raw test set shape \",test_data.shape)\n",
    "\n",
    "# eliminate NaN's\n",
    "test_data = np.delete(test_data, np.unique(np.argwhere(np.isnan(test_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "train_data = np.delete(train_data, np.unique(np.argwhere(np.isnan(train_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "\n",
    "print(\"Train set shape W/O NAN \",train_data.shape)\n",
    "print(\"Test set shape W/O NAN \",test_data.shape)\n",
    "\n",
    "\n",
    "Y_train_orig = train_data[:,0].astype(int)\n",
    "X_train_orig = train_data[:,3:]\n",
    "\n",
    "\n",
    "Y_test_orig = test_data[:,0].astype(int)\n",
    "X_test_orig = test_data[:,3:]\n",
    "\n",
    "\n",
    "print(\"Final train set shape \",X_train_orig.shape)\n",
    "print(\"Final train expected outcome set shape \",Y_train_orig.shape)\n",
    "\n",
    "\n",
    "print(\"Final test set shape \",X_test_orig.shape)\n",
    "print(\"Final test expected outcome set shape \",Y_test_orig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensie combined dataframe with NaN samples shape  (10462, 304)\n",
      "Appended combined dataframe shape  (3377, 903)\n"
     ]
    }
   ],
   "source": [
    "## Combining the raw provided ShuffleMaster train & test tables for AzureML modeling\n",
    "sensie_times = genfromtxt('sensie_timeseries_data.csv', delimiter=',', skip_header=0)\n",
    "\n",
    "print(\"Sensie combined dataframe with NaN samples shape \",sensie_times.shape)\n",
    "print(\"Appended combined dataframe shape \",sensie.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the R prepared dataset for ShuffleMaster train & test with gyro axis dimensions moved\n",
    "sensie_times = genfromtxt('sensie_timeseries_data.csv', delimiter=',', skip_header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10461.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>10461.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.572125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074849</td>\n",
       "      <td>0.139771</td>\n",
       "      <td>0.140594</td>\n",
       "      <td>0.144402</td>\n",
       "      <td>0.148421</td>\n",
       "      <td>0.154346</td>\n",
       "      <td>0.160457</td>\n",
       "      <td>0.163855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263161</td>\n",
       "      <td>1.016153</td>\n",
       "      <td>1.032741</td>\n",
       "      <td>1.076718</td>\n",
       "      <td>1.127894</td>\n",
       "      <td>1.189361</td>\n",
       "      <td>1.275561</td>\n",
       "      <td>1.382131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339108</td>\n",
       "      <td>0.327837</td>\n",
       "      <td>0.312047</td>\n",
       "      <td>0.302904</td>\n",
       "      <td>0.294903</td>\n",
       "      <td>0.287272</td>\n",
       "      <td>0.271625</td>\n",
       "      <td>0.259144</td>\n",
       "      <td>0.235860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.802093</td>\n",
       "      <td>-7.904702</td>\n",
       "      <td>-12.558128</td>\n",
       "      <td>-13.536951</td>\n",
       "      <td>-9.883625</td>\n",
       "      <td>-10.004488</td>\n",
       "      <td>-10.340969</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.774730</td>\n",
       "      <td>-12.436901</td>\n",
       "      <td>-12.004780</td>\n",
       "      <td>-11.543473</td>\n",
       "      <td>-10.998742</td>\n",
       "      <td>-10.348278</td>\n",
       "      <td>-9.600002</td>\n",
       "      <td>-8.776423</td>\n",
       "      <td>-7.910557</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.089571</td>\n",
       "      <td>-0.099986</td>\n",
       "      <td>-0.115621</td>\n",
       "      <td>-0.127393</td>\n",
       "      <td>-0.134823</td>\n",
       "      <td>-0.146445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042738</td>\n",
       "      <td>0.040326</td>\n",
       "      <td>0.035076</td>\n",
       "      <td>0.029887</td>\n",
       "      <td>0.025220</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235334</td>\n",
       "      <td>0.241262</td>\n",
       "      <td>0.246228</td>\n",
       "      <td>0.250459</td>\n",
       "      <td>0.257248</td>\n",
       "      <td>0.270023</td>\n",
       "      <td>0.268749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.603062</td>\n",
       "      <td>9.373840</td>\n",
       "      <td>10.935042</td>\n",
       "      <td>12.297511</td>\n",
       "      <td>13.473264</td>\n",
       "      <td>15.039717</td>\n",
       "      <td>17.346870</td>\n",
       "      <td>...</td>\n",
       "      <td>5.767133</td>\n",
       "      <td>5.486417</td>\n",
       "      <td>5.547605</td>\n",
       "      <td>5.573140</td>\n",
       "      <td>5.585373</td>\n",
       "      <td>5.551894</td>\n",
       "      <td>5.467457</td>\n",
       "      <td>5.333794</td>\n",
       "      <td>5.076385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1             2             3             4    \\\n",
       "count  10461.000000  0.0  10461.000000  10461.000000  10461.000000   \n",
       "mean       0.572125  NaN      0.074849      0.139771      0.140594   \n",
       "std        0.494794  NaN      0.263161      1.016153      1.032741   \n",
       "min        0.000000  NaN      0.000000     -7.802093     -7.904702   \n",
       "25%        0.000000  NaN      0.000000     -0.080729     -0.089571   \n",
       "50%        1.000000  NaN      0.000000      0.042738      0.040326   \n",
       "75%        1.000000  NaN      0.000000      0.235334      0.241262   \n",
       "max        1.000000  NaN      1.000000     10.603062      9.373840   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  10461.000000  10461.000000  10461.000000  10461.000000  10461.000000   \n",
       "mean       0.144402      0.148421      0.154346      0.160457      0.163855   \n",
       "std        1.076718      1.127894      1.189361      1.275561      1.382131   \n",
       "min      -12.558128    -13.536951     -9.883625    -10.004488    -10.340969   \n",
       "25%       -0.099986     -0.115621     -0.127393     -0.134823     -0.146445   \n",
       "50%        0.035076      0.029887      0.025220      0.021309      0.021522   \n",
       "75%        0.246228      0.250459      0.257248      0.270023      0.268749   \n",
       "max       10.935042     12.297511     13.473264     15.039717     17.346870   \n",
       "\n",
       "      ...            294           295           296           297  \\\n",
       "count ...   10461.000000  10461.000000  10461.000000  10461.000000   \n",
       "mean  ...       0.010979      0.010635      0.010402      0.009567   \n",
       "std   ...       0.339108      0.327837      0.312047      0.302904   \n",
       "min   ...     -12.774730    -12.436901    -12.004780    -11.543473   \n",
       "25%   ...       0.000000      0.000000      0.000000      0.000000   \n",
       "50%   ...       0.000000      0.000000      0.000000      0.000000   \n",
       "75%   ...       0.000000      0.000000      0.000000      0.000000   \n",
       "max   ...       5.767133      5.486417      5.547605      5.573140   \n",
       "\n",
       "                298           299           300           301           302  \\\n",
       "count  10461.000000  10461.000000  10461.000000  10461.000000  10461.000000   \n",
       "mean       0.009564      0.009289      0.010372      0.009379      0.009868   \n",
       "std        0.294903      0.287272      0.271625      0.259144      0.235860   \n",
       "min      -10.998742    -10.348278     -9.600002     -8.776423     -7.910557   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        5.585373      5.551894      5.467457      5.333794      5.076385   \n",
       "\n",
       "       303  \n",
       "count  0.0  \n",
       "mean   NaN  \n",
       "std    NaN  \n",
       "min    NaN  \n",
       "25%    NaN  \n",
       "50%    NaN  \n",
       "75%    NaN  \n",
       "max    NaN  \n",
       "\n",
       "[8 rows x 304 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensie_times.shape\n",
    "\n",
    "import pandas as pd\n",
    "sensie_times = pd.DataFrame(sensie_times)\n",
    "sensie_times.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-efadfd6cb865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#eliminate NaN's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msensie_NaNelim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensie_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensie_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "\n",
    "#eliminate NaN's\n",
    "sensie_NaNelim = np.delete(sensie_times, np.unique(np.argwhere(np.isnan(sensie_times[:,3:])).T[0].flatten('C')), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress free\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-5f964bcb70da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msensie_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensie_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1120\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# print some range of Sress free samples\n",
    "print(\"Stress free\")\n",
    "\n",
    "for i in range(2,3):\n",
    "    if sensie_times[i]:\n",
    "        plt.plot((sensie_times[i]))\n",
    "\n",
    "# print (\"y = \" + str(Y_test_orig[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some range of Sressfull samples\n",
    "\n",
    "print(\"Stress full\")\n",
    "for i in range(300,320):\n",
    "    if not Y_train_orig[i]:\n",
    "        plt.plot((X_train_orig[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {'state': ['Ohio', 'CA'], 'year': [2000, 2010]}\n",
    "df1 = pd.DataFrame(dict1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(2, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train set shape  (2440, 903)\n",
      "Full test set shape  (1045, 903)\n",
      "Train set shape without NAN records  (2363, 903)\n",
      "Test set shape without NAN records  (1014, 903)\n",
      "Final train set shape  (2363, 900)\n",
      "Final train expected outcome set shape  (2363,)\n",
      "Final test set shape  (1014, 900)\n",
      "Final test expected outcome set shape  (1014,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "# data format being loaded: \n",
    "# no headers\n",
    "# first column is the \"tag\" or expected outcom, 0 is \"Stress present\", 1 is \"Stress free\"\n",
    "# second column is the user's email\n",
    "# third column indicates if the user is left handed (represented by a 1) or right handed (represented by 0)\n",
    "# columns 4 to 903 (inclusive) represent gyroscope data gatered for 3 seconds at 100Hz \n",
    "# columns 4 to 303 (inclusive) are for Yaw\n",
    "# columns 304 to 603 (inclusive) are for Roll\n",
    "# columns 604 to 903 (inclusive) are for Pitch\n",
    "\n",
    "test_data = genfromtxt('MasterShuffle_test.csv', delimiter=',', skip_header=1)\n",
    "train_data = genfromtxt('MasterShuffle_train.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Full train set shape \",train_data.shape)\n",
    "print(\"Full test set shape \",test_data.shape)\n",
    "\n",
    "\n",
    "#eliminate NaN's\n",
    "test_data = np.delete(test_data, np.unique(np.argwhere(np.isnan(test_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "train_data = np.delete(train_data, np.unique(np.argwhere(np.isnan(train_data[:,3:])).T[0].flatten('C')), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train set shape without NAN records \",train_data.shape)\n",
    "print(\"Test set shape without NAN records \",test_data.shape)\n",
    "\n",
    "\n",
    "Y_train_orig = train_data[:,0].astype(int)\n",
    "X_train_orig = train_data[:,3:]\n",
    "\n",
    "\n",
    "Y_test_orig = test_data[:,0].astype(int)\n",
    "X_test_orig = test_data[:,3:]\n",
    "\n",
    "\n",
    "print(\"Final train set shape \",X_train_orig.shape)\n",
    "print(\"Final train expected outcome set shape \",Y_train_orig.shape)\n",
    "\n",
    "\n",
    "print(\"Final test set shape \",X_test_orig.shape)\n",
    "print(\"Final test expected outcome set shape \",Y_test_orig.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Constants\n",
    "\n",
    "# Those are separate normalised input features for the neural network\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    \"body_acc_x_\",\n",
    "    \"body_acc_y_\",\n",
    "    \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"STRESSED\", \n",
    "    \"NOT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Additionnal Parameters:</b><br>\n",
    "\n",
    "Here are some core parameter definitions for the training.\n",
    "\n",
    "The whole neural network's structure could be summarised by enumerating those parameters and the fact an LSTM is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363\n",
      "1014\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "training_data_count = len(X_train_orig)\n",
    "test_data_count = len(X_test_orig)\n",
    "n_steps = len(X_train_orig[0])\n",
    "##n_input = len(X_train_orig[0][0])\n",
    "\n",
    "print(training_data_count)\n",
    "print(test_data_count)\n",
    "print(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-01844123148d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some useful info to get an insight on dataset's shape and normalisation:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(X shape, y shape, every X's mean, every X's standard deviation)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_orig' is not defined"
     ]
    }
   ],
   "source": [
    "# Input Data \n",
    "\n",
    "training_data_count = len(X_train_orig)  # 2363 training series (with 50% overlap between each series)\n",
    "test_data_count = len(X_test_orig)  # 1014 testing series\n",
    "n_steps = len(X_train_orig[0])  # 900 timesteps per series = 3 * 3 sec * 100 Hz\n",
    "# n_input = len(X_train_orig[0][0])  # This will have to be hardcoded\n",
    "n_input = 3\n",
    "\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "\n",
    "n_hidden = 32 # Hidden layer num of features\n",
    "n_classes = 6 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "batch_size = 1500\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test_orig.shape, y_test_orig.shape, np.mean(X_test_orig), np.std(X_test_orig))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download necessary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mash/kdata/kaggle\n",
      "Introduction to TensorFlow and Sentiment Analysis.pdf\n",
      "Kaggle_001 - exploratory analysis.ipynb\n",
      "MashModel.ipynb\n",
      "README.md\n",
      "Sensie - hacking healthcare hackathon v1.ipynb\n",
      "TensorFlow_Regression.html\n",
      "TensorFlow_Regression.ipynb\n",
      "classes.csv\n",
      "directoryImageID_explore.R\n",
      "image001.jpg\n",
      "nuclei.html\n",
      "nuclei.ipynb\n",
      "nuclei.yml\n",
      "stuff.csv\n"
     ]
    }
   ],
   "source": [
    "!pwd && ls\n",
    "\n",
    "test_data = genfromtxt('/Users/mash/Downloads/Sensie_download_02-16-2018/'+'sensie_prepared_data.csv', delimiter=',', skip_header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mash/kdata/kaggle'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ERRORS OUT\n",
    "\n",
    "download_path = \"~/Users/mash/Downloads/Sensie_download_02-16-2018/\"\n",
    "def load_data(datafile):\n",
    "    time_series_data = []\n",
    "    \n",
    "    for file_path in datafile:\n",
    "        file = open(file_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        time_series_data.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "    \n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "data = load_data(download_path + 'sensie_prepared_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.        ,  8.63157895,  9.26315789,  9.89473684, 10.52631579,\n",
       "       11.15789474, 11.78947368, 12.42105263, 13.05263158, 13.68421053,\n",
       "       14.31578947, 14.94736842, 15.57894737, 16.21052632, 16.84210526,\n",
       "       17.47368421, 18.10526316, 18.73684211, 19.36842105, 20.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(8,20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
