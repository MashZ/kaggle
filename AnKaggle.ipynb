{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf            \n",
    "import sklearn.model_selection    \n",
    "import keras.preprocessing.image  \n",
    "import datetime                   \n",
    "import skimage.io           \n",
    "import sys                        \n",
    "import tqdm                       \n",
    "import seaborn as sns             \n",
    "import matplotlib.cm as cm        \n",
    "%matplotlib inline       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants.\n",
    "IMG_WIDTH = 256     \n",
    "IMG_HEIGHT = 256      \n",
    "IMG_CHANNELS = 3      \n",
    "CW_DIR = os.getcwd()  \n",
    "TRAIN_DIR = os.path.join(CW_DIR, 'input', 'stage1_train')\n",
    "TEST_DIR = os.path.join(CW_DIR, 'input', 'stage1_test')\n",
    "IMG_TYPE = '.png'         \n",
    "IMG_DIR_NAME = 'images'   \n",
    "MASK_DIR_NAME = 'masks'   \n",
    "LOGS_DIR_NAME = 'logs'    \n",
    "SAVES_DIR_NAME = 'saves'  \n",
    "SEED = 42                 \n",
    "\n",
    "# Global variables.\n",
    "min_object_size = 1       # Minimal nucleous size in pixels\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test_pred_proba = {}\n",
    "y_test_pred = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate lookup table for quick reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = os.listdir(TRAIN_DIR)\n",
    "id_list.remove('.DS_Store')\n",
    "\n",
    "lookup_table = pd.DataFrame()\n",
    "tmp = []\n",
    "for i in np.arange(0, len(id_list)):\n",
    "    img_name_id = id_list[i]\n",
    "    file = \"input/stage1_train/{}/images/{}.png\".format(id_list[i], id_list[i])\n",
    "    masks_path = \"input/stage1_train/{}/masks/*.png\".format(id_list[i])\n",
    "    image = cv2.imread(file)\n",
    "    height, width, channels = image.shape\n",
    "    tmp.append(['{}'.format(img_name_id), width, height])\n",
    "lookup_table = pd.DataFrame(tmp, columns = ['img_id', 'img_width', 'img_height'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_names = {0: \"nissl-stained\", \n",
    "              1: \"fluorescent\", \n",
    "              2: \"bright-field\"}\n",
    "\n",
    "def get_violet_num(img):\n",
    "    violet_num = 0\n",
    "    h, w = img.shape[:2]\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if img[y, x][0] > img[y, x][1] and img[y, x][2] > img[y, x][1]:\n",
    "                violet_num += 1\n",
    "\n",
    "    return violet_num\n",
    "\n",
    "def get_microscopy_type(img):\n",
    "    violet_num = get_violet_num(img)\n",
    "    if violet_num > 0:\n",
    "        return 0\n",
    "    mean_int = img.mean()\n",
    "    if mean_int > 110:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "types_list=[]\n",
    "for i in lookup_table['img_id']:\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(i, i)\n",
    "    image = skimage.io.imread(file_path)\n",
    "    types_list.append(type_names[get_microscopy_type(image)])\n",
    "lookup_table['type'] = types_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = pd.DataFrame([[x] for x in zip(lookup_table['img_width'], \n",
    "                                          lookup_table['img_height'], lookup_table['type'])])\n",
    "df_shape[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "target_shape = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "def read_image(filepath, color=1, size=None):\n",
    "    img = cv2.imread(filepath, color)\n",
    "    if size:\n",
    "        img = cv2.resize(img, size, interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def read_mask(directory, size=None):\n",
    "    mask = np.zeros(image.shape[:1])\n",
    "    for file in os.listdir(directory):\n",
    "        mask_path = os.path.join(directory, file)\n",
    "        mask_tmp = read_image(mask_path, color=0, size=target_shape)\n",
    "        if not file: mask = mask_tmp\n",
    "        else: mask = np.maximum(mask, mask_tmp)\n",
    "    return mask\n",
    "\n",
    "bright_field = np.array(lookup_table[lookup_table['type']=='bright-field']['img_id']) \n",
    "nissl_stained = np.array(lookup_table[lookup_table['type']=='nissl-stained']['img_id']) \n",
    "fluorescence = np.array(lookup_table[lookup_table['type']=='fluorescent']['img_id']) \n",
    "\n",
    "print('Resizing and inverting bright-field images, resizing masks ...')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for i, filename in tqdm.tqdm(enumerate(bright_field), total=len(bright_field)):\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(filename, filename)\n",
    "    image = read_image(file_path, size=target_shape)\n",
    "    inv_image = skimage.util.invert(image)\n",
    "    x_train.append(inv_image)\n",
    "    for name in os.listdir(\"input/stage1_train/{}/masks/\".format(filename)):\n",
    "        masks_dir = \"input/stage1_train/{}/masks\".format(filename)\n",
    "        masks = read_mask(masks_dir, size=target_shape)    \n",
    "    y_train.append(masks)\n",
    "\n",
    "print('Resizing, converting and inverting nissl_stained images, resizing masks ...')\n",
    "sys.stdout.flush()\n",
    "    \n",
    "for i, filename in tqdm.tqdm(enumerate(nissl_stained), total=len(nissl_stained)):\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(filename, filename)\n",
    "    image = read_image(file_path, size=target_shape, color=0)\n",
    "    inv_image = skimage.util.invert(image)\n",
    "    stacked_img = np.stack((inv_image,)*3, -1)\n",
    "    x_train.append(stacked_img)\n",
    "    for name in os.listdir(\"input/stage1_train/{}/masks/\".format(filename)):\n",
    "        masks_dir = \"input/stage1_train/{}/masks\".format(filename)\n",
    "        masks = read_mask(masks_dir, size=target_shape)    \n",
    "    y_train.append(masks)\n",
    "\n",
    "print('Resizing, fluorescent images, resizing masks ...')\n",
    "sys.stdout.flush()    \n",
    "    \n",
    "for i, filename in tqdm.tqdm(enumerate(fluorescence), total=len(fluorescence)):\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(filename, filename)\n",
    "    image = read_image(file_path, size=target_shape)\n",
    "    x_train.append(image)\n",
    "    for name in os.listdir(\"input/stage1_train/{}/masks/\".format(filename)):\n",
    "        masks_dir = \"input/stage1_train/{}/masks\".format(filename)\n",
    "        masks = read_mask(masks_dir, size=target_shape)    \n",
    "    y_train.append(masks)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.expand_dims(np.array(y_train), axis=4)\n",
    "\n",
    "print('These will be the model inputs')\n",
    "print('x_train.shape: {} of dtype {}'.format(x_train.shape, x_train.dtype))\n",
    "print('y_train.shape: {} of dtype {}'.format(y_train.shape, x_train.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.random.randint(len(x_train))\n",
    "fig, axs = plt.subplots(1,2,figsize=(20,20))\n",
    "axs[0].imshow(x_train[n])\n",
    "axs[1].imshow(y_train[n,:,:,0], cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train', x_train)\n",
    "np.save('y_train', y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 256, 256, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('x_train.npy')[:30]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/planetx/Applications/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 186s 6s/step - loss: 3.2568 - acc: 0.0258\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 185s 6s/step - loss: 0.5980 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 183s 6s/step - loss: 0.5345 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.4685 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 179s 6s/step - loss: 0.4015 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 183s 6s/step - loss: 0.3383 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 183s 6s/step - loss: 0.2702 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 185s 6s/step - loss: 0.2034 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 183s 6s/step - loss: 0.1391 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 172s 6s/step - loss: 0.0722 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a294940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dense, Dropout, Flatten, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate, Add\n",
    "import graphviz\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda,force_device=True,floatX=float32\"\n",
    "import theano\n",
    "\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "inputs = Input((img_rows, img_cols,3))\n",
    "#x_train = np.random.random((100, 128, 128, 3))\n",
    "#y_train = np.random.random((100, 128, 128, 1))\n",
    "x_train = np.load('x_train.npy')[:30]\n",
    "y_train = np.load('y_train.npy')[:30]\n",
    "\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = np.random.random((20, 100, 100, 1))\n",
    "\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv11 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)\n",
    "\n",
    "\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv22 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)\n",
    "\n",
    "\n",
    "conv3 = Conv2D(256, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv33 = Conv2D(256, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)\n",
    "\n",
    "\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv44 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv44)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2),padding = 'same')(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv55 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv55)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = Add()([drop4,up6])\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = Add()([conv3,up7])\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = Add()([conv2,up8])\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = Add()([conv1,up9])\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs = Tensor(inputs), outputs=Tensor(conv10))\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify score metrics for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate masks from test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:00, 131.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "IMG_WIDTH = 256     \n",
    "IMG_HEIGHT = 256      \n",
    "\n",
    "target_shape = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "def read_image(filepath, color=1, size=None):\n",
    "    img = cv2.imread(filepath, color)\n",
    "    if size:\n",
    "        img = cv2.resize(img, size, \n",
    "                         interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "x_test = []\n",
    "test_list=os.listdir('input/stage1_test/')\n",
    "for i, filename in tqdm.tqdm(enumerate(test_list)):\n",
    "    file_path = \"input/stage1_test/{}/images/{}.png\".format(filename, filename)\n",
    "    image = read_image(file_path, size=target_shape)\n",
    "    x_test.append(image)\n",
    "x_test = np.array(x_test)\n",
    "y_file1 = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 256, 256, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
