{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf            \n",
    "import sklearn.model_selection    \n",
    "import keras.preprocessing.image  \n",
    "import datetime                   \n",
    "import skimage.io           \n",
    "import sys                        \n",
    "import tqdm                       \n",
    "import seaborn as sns             \n",
    "import matplotlib.cm as cm        \n",
    "%matplotlib inline       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants.\n",
    "IMG_WIDTH = 256     \n",
    "IMG_HEIGHT = 256      \n",
    "IMG_CHANNELS = 3      \n",
    "CW_DIR = os.getcwd()  \n",
    "TRAIN_DIR = os.path.join(CW_DIR, 'input', 'stage1_train')\n",
    "TEST_DIR = os.path.join(CW_DIR, 'input', 'stage1_test')\n",
    "IMG_TYPE = '.png'         \n",
    "IMG_DIR_NAME = 'images'   \n",
    "MASK_DIR_NAME = 'masks'   \n",
    "LOGS_DIR_NAME = 'logs'    \n",
    "SAVES_DIR_NAME = 'saves'  \n",
    "SEED = 42                 \n",
    "\n",
    "# Global variables.\n",
    "min_object_size = 1       # Minimal nucleous size in pixels\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test_pred_proba = {}\n",
    "y_test_pred = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate lookup table for quick reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = os.listdir(TRAIN_DIR)\n",
    "id_list.remove('.DS_Store')\n",
    "\n",
    "lookup_table = pd.DataFrame()\n",
    "tmp = []\n",
    "for i in np.arange(0, len(id_list)):\n",
    "    img_name_id = id_list[i]\n",
    "    file = \"input/stage1_train/{}/images/{}.png\".format(id_list[i], id_list[i])\n",
    "    masks_path = \"input/stage1_train/{}/masks/*.png\".format(id_list[i])\n",
    "    image = cv2.imread(file)\n",
    "    height, width, channels = image.shape\n",
    "    tmp.append(['{}'.format(img_name_id), width, height])\n",
    "lookup_table = pd.DataFrame(tmp, columns = ['img_id', 'img_width', 'img_height'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_names = {0: \"nissl-stained\", \n",
    "              1: \"fluorescent\", \n",
    "              2: \"bright-field\"}\n",
    "\n",
    "def get_violet_num(img):\n",
    "    violet_num = 0\n",
    "    h, w = img.shape[:2]\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if img[y, x][0] > img[y, x][1] and img[y, x][2] > img[y, x][1]:\n",
    "                violet_num += 1\n",
    "\n",
    "    return violet_num\n",
    "\n",
    "def get_microscopy_type(img):\n",
    "    violet_num = get_violet_num(img)\n",
    "    if violet_num > 0:\n",
    "        return 0\n",
    "    mean_int = img.mean()\n",
    "    if mean_int > 110:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "types_list=[]\n",
    "for i in lookup_table['img_id']:\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(i, i)\n",
    "    image = skimage.io.imread(file_path)\n",
    "    types_list.append(type_names[get_microscopy_type(image)])\n",
    "lookup_table['type'] = types_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = pd.DataFrame([[x] for x in zip(lookup_table['img_width'], \n",
    "                                          lookup_table['img_height'], lookup_table['type'])])\n",
    "df_shape[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "target_shape = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "def read_image(filepath, color=1, size=None):\n",
    "    img = cv2.imread(filepath, color)\n",
    "    if size:\n",
    "        img = cv2.resize(img, size, interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def read_mask(directory, size=None):\n",
    "    mask = np.zeros(image.shape[:1])\n",
    "    for file in os.listdir(directory):\n",
    "        mask_path = os.path.join(directory, file)\n",
    "        mask_tmp = read_image(mask_path, color=0, size=target_shape)\n",
    "        if not file: mask = mask_tmp\n",
    "        else: mask = np.maximum(mask, mask_tmp)\n",
    "    return mask\n",
    "\n",
    "bright_field = np.array(lookup_table[lookup_table['type']=='bright-field']['img_id']) \n",
    "nissl_stained = np.array(lookup_table[lookup_table['type']=='nissl-stained']['img_id']) \n",
    "fluorescence = np.array(lookup_table[lookup_table['type']=='fluorescent']['img_id']) \n",
    "\n",
    "print('Resizing and inverting bright-field images, resizing masks ...')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for i, filename in tqdm.tqdm(enumerate(bright_field), total=len(bright_field)):\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(filename, filename)\n",
    "    image = read_image(file_path, size=target_shape)\n",
    "    inv_image = skimage.util.invert(image)\n",
    "    x_train.append(inv_image)\n",
    "    for name in os.listdir(\"input/stage1_train/{}/masks/\".format(filename)):\n",
    "        masks_dir = \"input/stage1_train/{}/masks\".format(filename)\n",
    "        masks = read_mask(masks_dir, size=target_shape)    \n",
    "    y_train.append(masks)\n",
    "\n",
    "print('Resizing, converting and inverting nissl_stained images, resizing masks ...')\n",
    "sys.stdout.flush()\n",
    "    \n",
    "for i, filename in tqdm.tqdm(enumerate(nissl_stained), total=len(nissl_stained)):\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(filename, filename)\n",
    "    image = read_image(file_path, size=target_shape, color=0)\n",
    "    inv_image = skimage.util.invert(image)\n",
    "    stacked_img = np.stack((inv_image,)*3, -1)\n",
    "    x_train.append(stacked_img)\n",
    "    for name in os.listdir(\"input/stage1_train/{}/masks/\".format(filename)):\n",
    "        masks_dir = \"input/stage1_train/{}/masks\".format(filename)\n",
    "        masks = read_mask(masks_dir, size=target_shape)    \n",
    "    y_train.append(masks)\n",
    "\n",
    "print('Resizing, fluorescent images, resizing masks ...')\n",
    "sys.stdout.flush()    \n",
    "    \n",
    "for i, filename in tqdm.tqdm(enumerate(fluorescence), total=len(fluorescence)):\n",
    "    file_path = \"input/stage1_train/{}/images/{}.png\".format(filename, filename)\n",
    "    image = read_image(file_path, size=target_shape)\n",
    "    x_train.append(image)\n",
    "    for name in os.listdir(\"input/stage1_train/{}/masks/\".format(filename)):\n",
    "        masks_dir = \"input/stage1_train/{}/masks\".format(filename)\n",
    "        masks = read_mask(masks_dir, size=target_shape)    \n",
    "    y_train.append(masks)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.expand_dims(np.array(y_train), axis=4)\n",
    "\n",
    "print('These will be the model inputs')\n",
    "print('x_train.shape: {} of dtype {}'.format(x_train.shape, x_train.dtype))\n",
    "print('y_train.shape: {} of dtype {}'.format(y_train.shape, x_train.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.random.randint(len(x_train))\n",
    "fig, axs = plt.subplots(1,2,figsize=(20,20))\n",
    "axs[0].imshow(x_train[n])\n",
    "axs[1].imshow(y_train[n,:,:,0], cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train', x_train)\n",
    "np.save('y_train', y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 256, 256, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('x_train.npy')[:30]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "30/30 [==============================] - 207s 7s/step - loss: 3.6299 - acc: 0.0349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3bc9c390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dense, Dropout, Flatten, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate, Add\n",
    "import graphviz\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda,force_device=True,floatX=float32\"\n",
    "import theano\n",
    "\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "inputs = Input((img_rows, img_cols,3))\n",
    "#x_train = np.random.random((100, 128, 128, 3))\n",
    "#y_train = np.random.random((100, 128, 128, 1))\n",
    "x_train = np.load('x_train.npy')[:30]\n",
    "y_train = np.load('y_train.npy')[:30]\n",
    "\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = np.random.random((20, 100, 100, 1))\n",
    "\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv11 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)\n",
    "\n",
    "\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv22 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)\n",
    "\n",
    "\n",
    "conv3 = Conv2D(256, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv33 = Conv2D(256, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)\n",
    "\n",
    "\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv44 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv44)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2),padding = 'same')(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv55 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv55)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = Add()([drop4,up6])\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = Add()([conv3,up7])\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = Add()([conv2,up8])\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = Add()([conv1,up9])\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs = inputs, outputs=conv10)\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify score metrics for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('x_train.npy')[31:33]\n",
    "y_test = np.load('y_train.npy')[31:33]\n",
    "\n",
    "#y_pred = model.predict(np.expand_dims(x_test, axis=0)) #use this ONLY if your x_test has only one image\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.segmentation\n",
    "\n",
    "image = x_test\n",
    "masks = y_test.squeeze()\n",
    "num,height, width, _ = image.shape\n",
    "num_masks = image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_mask(mask, cutoff=.5):\n",
    "    \"\"\"Object segmentation by labeling the mask.\"\"\"\n",
    "    mask = mask.reshape(mask.shape[0], mask.shape[1])\n",
    "    lab_mask = skimage.morphology.label(mask > cutoff)\n",
    "    (mask_labels, mask_sizes) = np.unique(lab_mask, return_counts=True)\n",
    "    return lab_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole block should be part of a for loop, running through all the pairs of groud truth masks (which are the sub-arrays of `y_test[0]`, having shape 256,256) and the predicted masks (sub-arrays of `y_pred[0]`). It should start with something like:\n",
    "\n",
    "`for i in len(y_pred[0]): true_mask = get_labeled_mask(masks[i]) ` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mask = get_labeled_mask(masks[0])\n",
    "pred_mask = get_labeled_mask(y_pred[0])\n",
    "\n",
    "# Compute number of objects\n",
    "true_objects = len(np.unique(true_mask))\n",
    "pred_objects = len(np.unique(pred_mask))\n",
    "\n",
    "# Compute intersection between all objects\n",
    "intersection = np.histogram2d(true_mask.flatten(), pred_mask.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "# Compute areas (needed for finding the union between all objects)\n",
    "area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "area_true = np.expand_dims(area_true, -1)\n",
    "area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "# Compute union\n",
    "union = area_true + area_pred - intersection\n",
    "\n",
    "# Exclude background from the analysis\n",
    "intersection = intersection[1:,1:]\n",
    "union = union[1:,1:]\n",
    "union[union == 0] = 1e-9\n",
    "\n",
    "# Compute the intersection over union\n",
    "iou = intersection / union\n",
    "\n",
    "# Precision helper function\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "    p = tp / (tp + fp + fn)\n",
    "    return tp, fp, fn, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, instead of using `prec = []` you should build a pd.DataFrame or an np.array where you append the values obtained at every for loop of the previous block. The values then have to be averaged per each threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500\t0\t0\t24\t0.000\n",
      "0.550\t0\t0\t24\t0.000\n",
      "0.600\t0\t0\t24\t0.000\n",
      "0.650\t0\t0\t24\t0.000\n",
      "0.700\t0\t0\t24\t0.000\n",
      "0.750\t0\t0\t24\t0.000\n",
      "0.800\t0\t0\t24\t0.000\n",
      "0.850\t0\t0\t24\t0.000\n",
      "0.900\t0\t0\t24\t0.000\n",
      "0.950\t0\t0\t24\t0.000\n",
      "AP\t-\t-\t-\t0.000\n"
     ]
    }
   ],
   "source": [
    "# Loop over IoU thresholds\n",
    "prec = []\n",
    "for t in np.arange(0.5, 1.0, 0.05):\n",
    "    tp, fp, fn, p = precision_at(t, iou)\n",
    "    print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "    prec.append(p)\n",
    "print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate masks from test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:00, 131.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "IMG_WIDTH = 256     \n",
    "IMG_HEIGHT = 256      \n",
    "\n",
    "target_shape = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# WARNING! THIS STILL NEED TO BE EDITED TO IMPLEMENT  DIFFERENT TRANSFORMATIONS FOR EACH TYPE OF IMAGES\n",
    "\n",
    "#test_list=os.listdir('input/stage1_test/')\n",
    "for i, filename in tqdm.tqdm(enumerate(x_test[0])):\n",
    "    #file_path = \"input/stage1_test/{}/images/{}.png\".format(filename, filename)\n",
    "    #image = read_image(file_path, size=target_shape)\n",
    "    x_test.append(image)\n",
    "x_test = np.array(x_test)\n",
    "y_file1 = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 256, 256, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
